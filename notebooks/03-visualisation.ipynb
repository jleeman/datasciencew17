{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"static/hyrule.css\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joshleeman/anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2881: FutureWarning: \n",
      "mpl_style had been deprecated and will be removed in a future version.\n",
      "Use `matplotlib.pyplot.style.use` instead.\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# pylab inline (either in the notebook or as an argument starting the notebook)\n",
    "# will by default load numpy as np and matplotlib.pylab as plt\n",
    "# Let's import everything else we used last time as well:\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from __future__ import division\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.mpl_style = 'default'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* learn how to group and aggregate data in pandas\n",
    "* learn how to visualise data with pandas\n",
    "* explain the difference between cast and melt in terms of a data frame\n",
    "* explore common visual relationships in data\n",
    "* learn two visualisation packages in python independent of pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Pandas Code\n",
    "\n",
    "Function         | Description\n",
    "-----------------|------------\n",
    "`.groupby()`     | Creates a groupby object in pandas. pass in either a string (one column) or a list (multiple columns)\n",
    "`.agg()`         | Aggregates data into a new DataFrame from a groupby object\n",
    "`.pivot_table()` | generates a pivot table, akin to those you'd expect in excel.\n",
    "`melt()`      | melts a DataFrame\n",
    "`.plot()`        | general plot using matplotlib of the columns provided, using the index as the x-axis\n",
    "`.hist()`        | generates a histogram using matplotlib of the columns provided, using the index as the x-axis\n",
    "`.boxplot()`     | generates a boxplot, which displays distribution via quartiles and outliers\n",
    "`pd.tools.plotting.scatter_matrix()` | a representation of histograms and scatterplots between columns <br /> Very common to import seperately using from pd.tools.plotting import scatter_matrix\n",
    "\n",
    "<br />\n",
    "### Matplotlib Basics\n",
    "\n",
    "Run this first to generate some data! They'll relate to the matplotlib basics below.\n",
    "\n",
    "```py\n",
    "X = np.linspace(-np.pi, np.pi, 256, endpoint=True)\n",
    "C, S = np.cos(X), np.sin(X)\n",
    "```\n",
    "\n",
    "Matplotlib functions will start with `plt`. In science we work with the concept of a `figure`, which is the space in which plots exist. While the below code is for `plot`, others are common as well (such as `hist`)\n",
    "\n",
    "Code | Description\n",
    "-----|------------\n",
    "`plt.figure(figsize=(8, 6), dpi=80)` | Sets a figure size of 8 by 6 inches, with a dpi of 80\n",
    "`plt.subplot(1, 1, 1)` | Create a new subplot from a grid of 1x1\n",
    "`plt.plot(X, C, color=\"blue\", linewidth=1.0, linestyle=\"-\")` | Plots cosine with a blue continuous line of width 1 (pixels)\n",
    "`plt.plot(X, S, color=\"green\", linewidth=1.0, linestyle=\"-\")` | Plots sine with a green continuous line of width 1 (pixels)\n",
    "`plt.xlim(-4.0, 4.0)` | Set x limits\n",
    "`plt.xticks(np.linspace(-4, 4, 9, endpoint=True))` | set x ticks\n",
    "`plt.ylim(-1.0, 1.0)` | Set y limits\n",
    "`plt.yticks(np.linspace(-1, 1, 5, endpoint=True))` | Set y ticks\n",
    "`plt.savefig(\"exercice_2.png\", dpi=72)` | Save figure using 72 dots per inch\n",
    "`plt.show()` | Show result on screen\n",
    "\n",
    "### Seaborn Basics\n",
    "\n",
    "We'll need to install seaborn first. You can do this with conda, a package installer for Anaconda. With this, conda might also update other packages. seaborn, once imported, takes over default matplotlib figures\n",
    "\n",
    "```sh\n",
    "cd ~/anaconda/bin\n",
    "conda install seaborn\n",
    "```\n",
    "\n",
    "Code | Description\n",
    "-----|------------\n",
    "`.set_style()`  | changes the current seaborn style. pass in parameters using a dictionary to update settings.\n",
    "`.axes_style()` | returns a dictionary of the current styles settings \n",
    "`.despine()`    | removes the top and right ticks on a chart"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Wine Data Set\n",
    "\n",
    "wine data set: https://archive.ics.uci.edu/ml/machine-learning-databases/wine/\n",
    "\n",
    "### Aggregating Data\n",
    "\n",
    "Last class was heavily focused on manipulating and subsetting individual observations in a data set. Exploring the raw data can be benefited by exploring the data as a whole through grouping and aggregations. Data aggregations and segmentations allow us to better understand and evaluate the properties of our data, particularly when we have a target variable in mind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns = \"\"\"-- The attributes are (dontated by Riccardo Leardi, \n",
    "    riclea@anchem.unige.it )\n",
    "    1) Alcohol\n",
    "    2) Malic acid\n",
    "    3) Ash\n",
    "    4) Alcalinity of ash  \n",
    "    5) Magnesium\n",
    "    6) Total phenols\n",
    "    7) Flavanoids\n",
    "    8) Nonflavanoid phenols\n",
    "    9) Proanthocyanins\n",
    "    10)Color intensity\n",
    "    11)Hue\n",
    "    12)OD280/OD315 of diluted wines\n",
    "    13)Proline\"\"\"\n",
    "\n",
    "# we can generate the columns list using some string and list functions.\n",
    "columns = columns.split('\\n')\n",
    "columns = [i.strip() for i in columns][2:]\n",
    "columns = [i.split(')')[1].strip().lower() for i in columns]\n",
    "cols = ['class']\n",
    "cols.extend(columns)\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data'\n",
    "wine = pd.read_csv(url, header=None)\n",
    "wine.columns = cols\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a groupby object:\n",
    "winegroups = wine.groupby('class')\n",
    "print type(winegroups)\n",
    "\n",
    "# groupby objects allow for some standard pandas calls:\n",
    "\n",
    "winegroups.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "winegroups.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Groupby objects also:\n",
    "## can work through selected columns\n",
    "\n",
    "#print winegroups.alcohol.mean()\n",
    "#print winegroups[['alcohol', 'ash']].median()\n",
    "\n",
    "## can work through aggregation dictionaries, which can reference the origin\n",
    "## groupby functions, or construct new functions.\n",
    "\n",
    "#print winegroups.agg({'alcohol': 'median'})\n",
    "print winegroups.agg({'alcohol': lambda alcohol: alcohol.nunique() / alcohol.count()})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot Tables\n",
    "\n",
    "Pivot tables are another aggregational tool provided in pandas. Use pivot tables when:\n",
    "\n",
    "1. we want to easily compare results of variables across groups\n",
    "2. we want to easily plot results along the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted_wine = wine.pivot_table(values='ash',\n",
    "                 columns='class',\n",
    "                 index='alcohol',\n",
    "                 aggfunc='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation shapes\n",
    "\n",
    "Sometimes we'll need to \"melt\" or \"cast\" our aggregation into a different shape, mostly in the context of plotting or applying aggregations as new fields in the original data set. Consider the use case of `melt()` here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted_wine_reset = pivoted_wine.reset_index()\n",
    "print pivoted_wine_reset.head()\n",
    "\n",
    "print pd.melt(pivoted_wine_reset,\n",
    "              id_vars=['alcohol'],\n",
    "              value_vars=[1, 2, 3],\n",
    "              value_name='count').dropna().head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation Practice\n",
    "\n",
    "1. This time, create a group by object on a rounded 'alcohol' field. You might want to break this out into:\n",
    "    * create a new column with the rounded alcohol content\n",
    "    * groupby on the new column\n",
    "2. Explore the statistics from `.describe()` in this new groupby object. Across the new groups, what is interesting? What isn't?\n",
    "3. Use a pivot table to show the count of each target type per rounded alcohol level.\n",
    "4. Finally, melt the pivot table so that the columns represent each grouping and a count of that group.\n",
    "5. **take a step back** What would be the `groupby()` code to create the same data frame you created in question 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = wine.alcohol.round()\n",
    "wine.append(x)\n",
    "alc_round = wine.groupby(x)\n",
    "alc_round.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseball Stats\n",
    "\n",
    "We'll pull in the Lahman batting stats for data visualisation. There's only one table in the Lahman database for now; we'll add more as class moves forward. As mentioned before, pandas can read in from databases as well, using a db engine /connection.\n",
    "\n",
    "Below includes the columns and their meanings:\n",
    "```\n",
    "player         Player ID code\n",
    "year           Year\n",
    "stint          player's stint (order of appearances within a season)\n",
    "team           Team\n",
    "lgID           League\n",
    "G              Games\n",
    "AB             At Bats\n",
    "R              Runs\n",
    "H              Hits\n",
    "X2B            Doubles\n",
    "X3B            Triples\n",
    "HR             Homeruns\n",
    "RBI            Runs Batted In\n",
    "SB             Stolen Bases\n",
    "CS             Caught Stealing\n",
    "BB             Base on Balls\n",
    "SO             Strikeouts\n",
    "IBB            Intentional walks\n",
    "HBP            Hit by pitch\n",
    "SH             Sacrifice hits\n",
    "SF             Sacrifice flies\n",
    "GIDP           Grounded into double plays\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"../data/lahman.sqlite\")\n",
    "df = pd.read_sql(\"SELECT * from batting\", con)\n",
    "df = df.convert_objects(convert_numeric=True)\n",
    "\n",
    "# Reminder: Many functions from data frames will work on groupby objects!\n",
    "# What is below doing?\n",
    "df.groupby('year').head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Variable Plots: Histograms and Boxplots\n",
    "\n",
    "To best understand a feature on its own, we explore it using histograms. Histograms help us understand the distribution of data.\n",
    "\n",
    "#### What shouild we be looking for?\n",
    "\n",
    "1. Width of the data. Use this alongside standard deviation to understand scope.\n",
    "2. Distributions. NYU has a [nice guideline](http://pages.stern.nyu.edu/~adamodar/New_Home_Page/StatFile/statdistns.htm) to consider. We'll go over distributions as they arise. But in particular:\n",
    "3. Expected vs Actual: Is this the shape we expected? Does it make sense given the feature? \n",
    "4. Segments: What jumps out as interesting? For example, are we interested in observing an 80/20 problem, or interested in the majority?\n",
    "\n",
    "#### Ways we generate histograms:\n",
    "\n",
    "1. `df.col.hist()` : pandas integrates with matplotlib to build histograms on the fly. Pass in multiple columns to generate multiple histograms at the same time.\n",
    "2. `plt.hist()`: direct matplotlib code.\n",
    "\n",
    "#### Ways we generate boxplots:\n",
    "\n",
    "1. `df.col.boxplot()` : pandas integration for boxplots. Pass in multiple columns to generate multiple boxplots at the same time.\n",
    "2. `plt.boxplot()`: direct matplotlib code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Histograms\n",
    "# pandas style\n",
    "df[['g', 'ab']].hist()\n",
    "\n",
    "# matplotlib style\n",
    "#sns.set_style('white') # sets seaborn \"white\" to the default matplotlib style\n",
    "#plt.figure(figsize=(8, 6), dpi=80)\n",
    "#plt.subplot(1, 1, 1)\n",
    "#plt.hist(df.g, bins=20)\n",
    "\n",
    "## Boxplots\n",
    "# pandas style\n",
    "#plt.figure(figsize=(8, 6), dpi=80)\n",
    "#df[['g', 'ab']].boxplot()\n",
    "#\n",
    "## matplotlib style\n",
    "#plt.figure(figsize=(8, 6), dpi=80)\n",
    "#plt.subplot(1, 1, 1)\n",
    "#plt.boxplot(df.g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doing histograms faster\n",
    "\n",
    "1. How do we use a for loop to generate a plot of each numeric field? Consider checking the fields `dtype` before making the plots\n",
    "2. Wrap your histogram three-liner as a function. We should be in the habit of always generating figures and subplots, but it's less necessary to have to write all code each time you want to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariable plots: Scatterplots\n",
    "\n",
    "While histograms allow us to explore fields individually, scatter plots allow us to compare and correlate data points. \n",
    "\n",
    "#### What to look for\n",
    "\n",
    "1. Degrees of correlation (+/-). Are the two features positively or negatively correlated? What's the impact of one on the other?\n",
    "2. Type of relationship. Is the relationship linear? Polynomial? Logarithmic? \n",
    "\n",
    "#### Ways we generate scatter plots:\n",
    "\n",
    "1. `df.plot(type='scatter')` : pandas integrates with matplotlib to build scatter plots on the fly.\n",
    "2. `plt.plot()`: direct matplotlib code. You'll have to specify the marker.\n",
    "2. `plt.scatter()`: simpler context for matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_year = df[df.year == 2014]\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# using plot and the '.' notation.\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(last_year.ab, last_year.h, '.')\n",
    "\n",
    "# using scatter, and setting additional parameters.\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.scatter(last_year.ab, last_year.h, s=last_year.hr**2, alpha=0.3, c='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other useful pandas plots\n",
    "\n",
    "#### Trellis Plotting\n",
    "\n",
    "Trellis plotting is a technique to group histograms or scatterplots based on a segmentation. This will be familiar to R users (the `lattice` package adds this functionality, as well as ggplot's `facet_grid`). Trellis plotting helps us easily identify how a feature can change dependent on another. Trellis plotting is built into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas.tools.rplot as rplot\n",
    "    \n",
    "plt.figure()\n",
    "plot = rplot.RPlot(last_year, x='hr')\n",
    "plot.add(rplot.TrellisGrid(['lg','.']))\n",
    "plot.add(rplot.GeomHistogram())\n",
    "print plot.render(plt.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A similar output can be done using the \"by\" argument in the plotting syntax (This would be more akin to `facet_wrap` in ggplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "df[df.stint < 5].hist('hr', by='stint')\n",
    "\n",
    "plt.figure()\n",
    "df[df.stint < 5].boxplot('hr', by='stint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter Matrix\n",
    "\n",
    "While doing this through each variable could be conveniently handled in a for loop or using a trellis plot, pandas includes a scatter_matrix which will provide both a histogram of each numeric field, but also a scatter plot for each field comparison. Use this wisely, as it's rather heavy plotting, and therefore, dependent on your data, memory intensive. You can, of course, subset to columns you are interested in comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = ['ab', 'h', 'X2b', 'X3b', 'hr',]\n",
    "pd.scatter_matrix(last_year[cols], figsize=(12, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupbys and grouped plotting\n",
    "\n",
    "One final technique to consider (for today) is how we can use groupby and plotting alongside each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "years_grouped = df.groupby('year')\n",
    "\n",
    "plt.figure()\n",
    "years_grouped.hr.agg(['mean']).plot()\n",
    "\n",
    "plt.figure()\n",
    "years_grouped.hr.agg(['sum']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On Your Own"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very famous data set called Fisher's Iris data is included in sklearn. Import it with the following code into pandas (otherwise, it's a numpy ndarray)\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_description = iris.DESCR\n",
    "irisdf = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "irisdf['target'] = iris.target\n",
    "print iris_description\n",
    "```\n",
    "\n",
    "1. describe, aggregate, and visualise the iris data set. what's interesting about it?\n",
    "    * be able to show both scatterplots and histograms using matplotlib, Trellis, and the scatter_matrix. Use the class target to group by.\n",
    "2. Which flowers are similar? Which seems to be in \"its own world?\"\n",
    "3. Write an .apply() function that would \"human learn\" the three flowers. It would be your best attempt to:\n",
    "    * split the flowers apart using the four columns\n",
    "    * assign either a 1, 2 or 3, similar to target\n",
    "    * test the performance of accuracy by measure how often your results match the original target vs the total count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review, Next Steps, Reading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 2: Due on Monday, Feb 9th\n",
    "* You'll be practicing this week's lectures in more detail with citibike data. Use the following [link](https://github.com/podopie/DAT18NYC/blob/master/assignments/02-data_manipulation_and_visualization.md) to get to the details.\n",
    "\n",
    "#### Additional Resources\n",
    "\n",
    "* Watch Andrew Montalenti's [\"Rapid Data Visualization\"](http://vimeo.com/79580138)\n",
    "   * Includes Pandas; D3.js; NVD3.js; Vega / Vincent; and PhantomJS. \n",
    "* View Wickham's [Grammar of Graphics Slides](http://www.slideshare.net/hadley/grammar-of-graphics-past-present-future)\n",
    "    * Or, read his [paper](http://vita.had.co.nz/papers/layered-grammar.html)\n",
    "* [another matplotlib tutorial](http://jakevdp.github.io/mpl_tutorial/)\n",
    "* [Principles of Analytic Graphics](https://github.com/DataScienceSpecialization/courses/blob/master/04_ExploratoryAnalysis/Principles/PrinciplesofAnalyticGraphics.pdf?raw=true)\n",
    "* [Matplotlib Docs](http://matplotlib.org/users/pyplot_tutorial.html)\n",
    "* [Pandas Docs](http://pandas.pydata.org/pandas-docs/stable/visualization.html)\n",
    "* [Choosing a Good Chart](http://extremepresentation.typepad.com/.shared/image.html?/photos/uncategorized/choosing_a_good_chart.jpg)\n",
    "* [Columbia's deck on visualisation](http://www2.research.att.com/~volinsky/DataMining/Columbia2011/Slides/Topic2-EDAViz.ppt)\n",
    "* [More practice with matplotlib and customisation](http://nbviewer.ipython.org/github/fonnesbeck/Bios366/blob/master/notebooks/Section2_4-Matplotlib.ipynb)\n",
    "\n",
    "#### Next Steps\n",
    "* We'll be learning and using statsmodels next week as a tool for further exploring and explaining data relationships. Consider going through [the documentation](http://statsmodels.sourceforge.net/stable/index.html) in your spare time to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
