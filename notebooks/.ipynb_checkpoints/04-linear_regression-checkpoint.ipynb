{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<link rel=\"stylesheet\" href=\"static/hyrule.css\" type=\"text/css\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regressions as an Exploratory Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* How to analyze the distributions in your data with scatterplots and histograms\n",
    "* How to use data relationships to get results\n",
    "* Interepretation of statsmodels coefficient tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code | description\n",
    "-----|------------\n",
    "`sm.qqplot()` | generates a qq plot using matplotlib. Arguments commonly include vector you want to use, and the distribution type.\n",
    "`smf.ols(formula, data)` | Using the statsmodels api, generates a ordinary least squares linear regression object. the formula is borrowed from R syntax, and can reference DataFrame columns\n",
    "`.fit()` | computes the results of the ols model object.  Effectively, it solves for $y = \\alpha x + \\beta + e$\n",
    "`.summary()` | returns the summary from the computed results from `.fit()`\n",
    "`sns.lmplot(x, y, data)` | performs a linear regression and plots the model against x and y. Very useful for representing single variable performance.\n",
    "`sm.stats.anova_lm()` | Generates an ANOVA (analysis of variance) table.\n",
    "`.get_influence().summary_table()` | Generates a table of information for the residuals of each observation from a given linear model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding distributions\n",
    "\n",
    "Load in the following data set about mammals and their sleeping patterns. The columns of the dataset are defined as followed:\n",
    "\n",
    "```\n",
    "name: common name\n",
    "genus\n",
    "vore: carnivore, omnivore or herbivore?\n",
    "order\n",
    "conservation: the conservation status of the animal\n",
    "sleep_total: total amount of sleep, in hours\n",
    "sleep_rem: rem sleep, in hours\n",
    "sleep_cycle: length of sleep cycle, in hours\n",
    "awake: amount of time spent awake, in hours\n",
    "brainwt: brain weight in kilograms\n",
    "bodywt: body weight in kilograms\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sleep_total</th>\n",
       "      <th>sleep_rem</th>\n",
       "      <th>sleep_cycle</th>\n",
       "      <th>awake</th>\n",
       "      <th>brainwt</th>\n",
       "      <th>bodywt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>83.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.433735</td>\n",
       "      <td>1.875410</td>\n",
       "      <td>0.439583</td>\n",
       "      <td>13.567470</td>\n",
       "      <td>0.281581</td>\n",
       "      <td>166.136349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.450357</td>\n",
       "      <td>1.298288</td>\n",
       "      <td>0.358680</td>\n",
       "      <td>4.452085</td>\n",
       "      <td>0.976414</td>\n",
       "      <td>786.839732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.850000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>10.250000</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.174000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.100000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>13.900000</td>\n",
       "      <td>0.012400</td>\n",
       "      <td>1.670000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.750000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>0.579167</td>\n",
       "      <td>16.150000</td>\n",
       "      <td>0.125500</td>\n",
       "      <td>41.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>19.900000</td>\n",
       "      <td>6.600000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>22.100000</td>\n",
       "      <td>5.712000</td>\n",
       "      <td>6654.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sleep_total  sleep_rem  sleep_cycle      awake    brainwt       bodywt\n",
       "count    83.000000  61.000000    32.000000  83.000000  56.000000    83.000000\n",
       "mean     10.433735   1.875410     0.439583  13.567470   0.281581   166.136349\n",
       "std       4.450357   1.298288     0.358680   4.452085   0.976414   786.839732\n",
       "min       1.900000   0.100000     0.116667   4.100000   0.000140     0.005000\n",
       "25%       7.850000   0.900000     0.183333  10.250000   0.002900     0.174000\n",
       "50%      10.100000   1.500000     0.333333  13.900000   0.012400     1.670000\n",
       "75%      13.750000   2.400000     0.579167  16.150000   0.125500    41.750000\n",
       "max      19.900000   6.600000     1.500000  22.100000   5.712000  6654.000000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_style('white')\n",
    "spat = pd.read_csv('../data/msleep.csv')\n",
    "\n",
    "pd.scatter_matrix(spat, figsize=[10, 10], alpha=0.2, diagonal='kde')\n",
    "spat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Already from quickly scanning the KDE (kernel density estimation) plots, we recognize a few interesting relationships. KDE, like histograms, allow us to quickly visualization the distribution of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.5\n"
     ]
    }
   ],
   "source": [
    "norm = pd.DataFrame({'d': np.random.normal(size=100)})\n",
    "n_bins = np.abs(spat['sleep_rem'].max() - spat['sleep_rem'].min())\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2,)\n",
    "print n_bins\n",
    "\n",
    "## New notation: what does the 'ax' argument do?\n",
    "#norm['d'].plot(ax=axes[0, 0], kind='kde')\n",
    "#norm['d'].hist(ax=axes[0, 1], bins=n_bins/2)\n",
    "#spat['awake'].plot(ax=axes[1, 0], kind='kde')\n",
    "#spat['awake'].hist(ax=axes[1, 1], bins=n_bins/2)\n",
    "#\n",
    "#print fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal distributions are defined by their mean and standard deviation. We primarily use them in data science as it often describes as a natural state, but also because it's easy to understand and calculate. \n",
    "\n",
    "Above, it appears that the awake hours (or sleeping hours, as that is 24 - awake hours) seems to fit pretty close to a normal distribution---but how close?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "qq = sorted(np.random.normal(spat['sleep_rem'].mean(), spat['sleep_rem'].std(), len(spat)))\n",
    "awake = sorted(spat['sleep_rem'])\n",
    "\n",
    "plt.plot(qq, awake, '.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we're looking at something similar to a \"qq plot.\" QQ plots determine how much your data is similar to a probability distribution. However, doing it the above way is obtrusive and obfuscates what we're handling. \n",
    "\n",
    "Statsmodels, a statistical library in python, can curate these very quickly for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Check sm.qqplot() configurations with shift+tab to see how you can change the distribution you are testing against!\n",
    "fig = sm.qqplot(spat['sleep_rem'], dist=stats.distributions.norm, line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our interpretation of the above plot would suggest a couple things:\n",
    "\n",
    "* this data set's \"awake\" variable does pretty well fitting to a normal distribution\n",
    "* the missing normalcy occurs around 20 hours of sleep--which is similar to the \"hump\" we saw in the histogram/KDE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your turn: Testing Distributions\n",
    "\n",
    "Walking through the same steps, see if there is a similar pattern for \"sleep_rem\". How would you explain the shape of the data to someone else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heavy tail distributions and power laws\n",
    "\n",
    "Notice in the data set above, body weight and brain weight are not normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2,)\n",
    "\n",
    "norm['d'].plot(ax=axes[0, 0], kind='kde')\n",
    "norm['d'].hist(ax=axes[0, 1], bins=n_bins/2)\n",
    "spat['brainwt'].plot(ax=axes[1, 0], kind='kde')\n",
    "spat['brainwt'].hist(ax=axes[1, 1], bins=n_bins/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(spat.brainwt, spat.awake, '.')\n",
    "# Clearly there isn't a linear relationship here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to handle heavy tail data is with a linear transformation. \n",
    "\n",
    "Transposing the body weight using log manipulates the data into a shape we better understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2,)\n",
    "\n",
    "ax[0, 0].hist(spat.bodywt)\n",
    "ax[0, 1].hist(np.log(spat.bodywt))\n",
    "ax[1, 0].plot(spat.bodywt, spat.awake, '.')\n",
    "ax[1, 1].plot(np.log(spat.bodywt), spat.awake, '.')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig = sm.qqplot(spat['bodywt'], dist=stats.distributions.norm, line='s')\n",
    "plt.show()\n",
    "\n",
    "fig = sm.qqplot(np.log(spat['bodywt']), dist=stats.distributions.norm, line='s')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that transforming data into some other \"space\" doesn't mean it's [right](http://vserver1.cscs.lsa.umich.edu/~crshalizi/weblog/491.html)!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding how good the relationship is - Linear Regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test the relationship between variables given it's statistical significance. A p-value is the probability that a correllation is due to randomness, or by chance. A low p-value means that the result is not due to randomness, while a high p-value means it is due to randomness. \n",
    "\n",
    "In statsmodels, we can use a coefficient table from the linear model to get our p-values. To start, observe the relationship between body mass and brain mass in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "# OLS, or ordinary least squares, takes a y (dependent variable) and X (independent variables) (formula = y ~ X)\n",
    "# Below, we copy the data frame and remove the na variables, and create a single variable linear model\n",
    "# to return a test statistic and p-value, to see how strong of a relationship bodyweight and brainweight have.\n",
    "\n",
    "spat_cleaned_up = pd.DataFrame(spat)\n",
    "spat_cleaned_up['bodywt'].dropna(inplace=True)\n",
    "spat_cleaned_up['brainwt'].dropna(inplace=True)\n",
    "spat_cleaned_up['log_bodywt'] = np.log(spat_cleaned_up['bodywt'])\n",
    "spat_cleaned_up['log_brainwt'] = np.log(spat_cleaned_up['brainwt'])\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1,ncols=2)\n",
    "\n",
    "axes[0].plot(spat_cleaned_up.bodywt, spat_cleaned_up.brainwt, 'g.')\n",
    "\n",
    "model = smf.ols(formula='brainwt ~ bodywt', data=spat_cleaned_up)\n",
    "results = model.fit()\n",
    "print 'NORMAL FIT SUMMARY'\n",
    "print(results.summary())\n",
    "print\n",
    "\n",
    "axes[1].plot(spat_cleaned_up.log_bodywt, spat_cleaned_up.log_brainwt, 'm.')\n",
    "\n",
    "log_model = smf.ols(formula='log_brainwt ~ log_bodywt', data=spat_cleaned_up)\n",
    "log_results = log_model.fit()\n",
    "print 'LOG-LOG FIT SUMMARY'\n",
    "print(log_results.summary())\n",
    "\n",
    "print fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another functionality of seaborn is that it can print out linear model figures as well. Here we can see the original plots, the model that fits, and a confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Original model\n",
    "print sns.lmplot(x='bodywt', y='brainwt', data=spat_cleaned_up)\n",
    "\n",
    "# New log-log model\n",
    "print sns.lmplot(x='log_bodywt', y='log_brainwt', data=spat_cleaned_up)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words/parts of the table we should know and understand (for now):\n",
    "\n",
    "value | description\n",
    "------|------------\n",
    "**<code>P>&#124;t&#124;</code>** | p values. In both cases we see significance in the relationship, but not with where the predicted y value starts\n",
    "**`t`** | t-value of the coefficients (which we'll talk about more next week). It's used to determine the p-values\n",
    "**`F-statistic`** and **`P(F-statistic)`** | A comparison of this how this data fits vs the same data set with less information. like the p-values above, the closer the f-statisitics p-value is to 0, the better this \"fit\"\n",
    "**`R-squared`** | NOT a value of R (correlation) ^2, but instead a representation of \"goodness of fit.\" For now, understand this as a value that primarily ranges between 0 and 1, 1 being the \"best\" fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though in both instances the p-value of the body weight is significant (p ~ 0), it's important to note that:\n",
    "\n",
    "* The \"goodness of fit\" in the log-log transform is higher than the non-transformed version\n",
    "* A scatter plot of each confirms that the relationship is a lot easier on the eyes as well in the log-log transform\n",
    "\n",
    "Therefore it's incredibly useful to work with both **visualizations** and **using models** to understand data relationships.\n",
    "\n",
    "Note that you can also get much of this information in an analysis of variance table (see below code), or further evaluate at a per-point basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print sm.stats.anova_lm(log_results, typ=2)\n",
    "print\n",
    "print log_results.get_influence().summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On Your Own\n",
    "\n",
    "**Are animal sleep patterns dependent on their weight?**\n",
    "\n",
    "We want to test the relationships between the hours of sleep_rem or sleep_cycle an animal gets, and either body weight or brain weight. Repeat the steps above in one or two cells to show:\n",
    "\n",
    "1. Is there a linear relationship between one of these variables and the number of hours?\n",
    "2. If so, what's the measure of goodness of fit?\n",
    "3. Does one seem to fit better than another?\n",
    "\n",
    "By practicing:\n",
    "\n",
    "* creating histograms, scatterplots, and qqplots\n",
    "* fitting a single variable linear model\n",
    "* reading and interpreting the returning summary table\n",
    "\n",
    "\n",
    "**ADVANCED**\n",
    "\n",
    "There are missing values all over the data set. Which variables seem easy to interpolate? Include your code.\n",
    "\n",
    "There are categorical variables that we did not use today in the data set. Consider exploring the usage of [pd.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.reshape.get_dummies.html) and creating a new model composed of the variables generated (try each at one time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review, next steps, practice\n",
    "\n",
    "* We've explored several data sets through the course so far, either captured in the `data` folder, or pulled from urls. In a similar vein, explore the relationships with variables, after determining a dependent variable, y.\n",
    "* Power laws are common in our data (with a warning!). One very common distribution in business data is the Pareto distribution.\n",
    "    * Learn about what they are [here](http://en.wikipedia.org/wiki/Pareto_distribution).\n",
    "    * See an application of it [here](http://www.hpl.hp.com/research/idl/papers/ranking/ranking.html)\n",
    "    * Read this Quora more specifically about [power laws](http://www.quora.com/In-what-conditions-would-you-expect-a-power-law-distribution-curve-to-emerge)\n",
    "* If you haven't yet, please review [Python OOP](http://learnpythonthehardway.org/book/ex40.html) by next class.\n",
    "* Also if you haven't yet, please bookmark all the following pages for a class \"documentation\" set:\n",
    "    * [pandas](http://pandas.pydata.org/pandas-docs/stable/)\n",
    "    * [numpy and scipy](http://docs.scipy.org/doc/)\n",
    "    * [matplotlib](matplotlib.org)\n",
    "    * [seaborn](http://stanford.edu/~mwaskom/software/seaborn/index.html)\n",
    "    * [statsmodels](http://statsmodels.sourceforge.net/)\n",
    "    * [sklearn](http://scikit-learn.org/stable/documentation.html)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
